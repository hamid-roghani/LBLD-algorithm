{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import groupby\n",
    "from math import ceil\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from pandas import DataFrame\n",
    "import collections\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "# ---------------------------------- Load Dataset -------------------------------------------\n",
    "dataset_name = \"karate\" # name of dataset\n",
    "path = \"./datasets/\" + dataset_name + \".txt\" # path to dataset\n",
    "iteration = 1           # number of iterations for label selection step (mostly is set to 1 or 2)\n",
    "merge_flag = 1         # merge_flag=0 -> do not merge //  merge_flag=1 -> do merge\n",
    "write_flag = 0        # 1 means write nodes labels to file. 0 means do not write\n",
    "modularity_flag = 1  # 1 means calculate modularity. 0 means do not calculate modularity\n",
    "NMI_flag = 1        # 1 means calculate NMI. 0 means do not calculate NMI\n",
    "# ------------------------- compute nodes neighbors and nodes degree --------------------------\n",
    "nodes_neighbors = {}\n",
    "\n",
    "i=0\n",
    "with open(path) as f:\n",
    "\n",
    "    for line in f:\n",
    "        row = str(line.strip()).split('\\n')[0].split('\\t')\n",
    "        temp_arrey = []\n",
    "        for j in row:\n",
    "            if j == '':\n",
    "                temp_arrey.append(-1)\n",
    "            if j != '':\n",
    "                temp_arrey.append(int(j))\n",
    "        nodes_neighbors.setdefault(i, []).append(temp_arrey)\n",
    "\n",
    "        if nodes_neighbors[i][0][0] != -1:\n",
    "            nodes_neighbors.setdefault(i, []).append(len(nodes_neighbors[i][0]))\n",
    "\n",
    "        elif nodes_neighbors[i][0][0] == -1:\n",
    "            nodes_neighbors.setdefault(i, []).append(0)\n",
    "        i = i+1  \n",
    "N = i # number of nodes\n",
    "start_time = time.time()\n",
    "# -----------------------------Compute node importance------------------------------\n",
    "\n",
    "for i in range(N):\n",
    "    CN_sum = 0\n",
    "    temp = []\n",
    "    d = {}\n",
    "    if nodes_neighbors[i][1] > 1:\n",
    "\n",
    "        for neighbor in nodes_neighbors[i][0]:\n",
    "\n",
    "            intersect = len(list(set(nodes_neighbors[i][0]) & set(nodes_neighbors[neighbor][0])))\n",
    "            union = nodes_neighbors[i][1] + nodes_neighbors[neighbor][1] - intersect\n",
    "\n",
    "            if nodes_neighbors[i][1] > nodes_neighbors[neighbor][1]:\n",
    "                difResult = 1 + len(set(nodes_neighbors[neighbor][0]).difference(set(nodes_neighbors[i][0])))\n",
    "            else:\n",
    "                difResult = 1 + len(set(nodes_neighbors[i][0]).difference(set(nodes_neighbors[neighbor][0])))\n",
    "\n",
    "            CN_sum = CN_sum + ((intersect / (intersect + union)) * (intersect / difResult))\n",
    "            d[neighbor] = (neighbor, ((intersect / (intersect + union)) * (intersect / difResult)))\n",
    "\n",
    "    elif nodes_neighbors[i][1] == 1:\n",
    "        CN_sum = 0\n",
    "        d[nodes_neighbors[i][0][0]] = (nodes_neighbors[i][0][0], 0)\n",
    "\n",
    "    elif nodes_neighbors[i][1] == 0:\n",
    "        CN_sum = 0\n",
    "        d[-1] = (-1,-1)\n",
    "\n",
    "    nodes_neighbors.setdefault(i, []).append(list(max(d.values(), key=itemgetter(1))))\n",
    "    nodes_neighbors.setdefault(i, []).append(([CN_sum, i, 0]))\n",
    "\n",
    "nodes_neighbors = {k: v for k, v in sorted(nodes_neighbors.items(), key=lambda item: item[1][3][0], reverse=True)}\n",
    "\n",
    "# --------------------------Select most similar neighbor-----------------------\n",
    "\n",
    "for i in range(N):\n",
    "    if nodes_neighbors[i][1] > 1:\n",
    "\n",
    "        if nodes_neighbors[i][2][1] == 0:  # if similarity is equal to 0, we select neighbor with highest degree\n",
    "            neighbors_degree = []\n",
    "\n",
    "            for j in nodes_neighbors[i][0]:\n",
    "                neighbors_degree.append((j, nodes_neighbors[j][1]))\n",
    "\n",
    "            max_degree_neighbor = max(neighbors_degree, key=itemgetter(1))[0]\n",
    "            nodes_neighbors.setdefault(i, []).append([max_degree_neighbor, -1])\n",
    "            nodes_neighbors[i][3][1] = max_degree_neighbor\n",
    "\n",
    "            continue\n",
    "        elif nodes_neighbors[i][2][1] != 0:\n",
    "\n",
    "            if nodes_neighbors[i][3][0] > nodes_neighbors[nodes_neighbors[i][2][0]][3][0]:\n",
    "                nodes_neighbors.setdefault(i, []).append([i, nodes_neighbors[i][2][0]])\n",
    "                nodes_neighbors[i][3][1] = i\n",
    "            else:\n",
    "                nodes_neighbors.setdefault(i, []).append([nodes_neighbors[i][2][0], nodes_neighbors[i][2][0]])\n",
    "                nodes_neighbors[i][3][1] = nodes_neighbors[i][2][0]\n",
    "    else:\n",
    "        nodes_neighbors.setdefault(i, []).append([i, -1])\n",
    "        nodes_neighbors[i][3][1] = i\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    nodes_neighbors[i][3][1] = nodes_neighbors[nodes_neighbors[i][4][0]][3][1]\n",
    "# ---------------------------- Top 5 percent important nodes -----------------------------\n",
    "top_5percent = ceil(N * 5 / 100)\n",
    "most_important = {}\n",
    "\n",
    "dict_items = nodes_neighbors.items()\n",
    "selected_items = list(dict_items)[:top_5percent]  # take top 5% items\n",
    "\n",
    "for i in range(top_5percent):\n",
    "    most_important[selected_items[i][0]] = (nodes_neighbors[selected_items[i][0]][4][1])\n",
    "\n",
    "for i in most_important:\n",
    "    temp_label = []\n",
    "    if nodes_neighbors[i][3][0] >= nodes_neighbors[most_important[i]][3][0]:\n",
    "        temp_label = nodes_neighbors[i][3][1]\n",
    "        nodes_neighbors[most_important[i]][3][1] = temp_label\n",
    "    else:\n",
    "        temp_label = nodes_neighbors[most_important[i]][3][1]\n",
    "        nodes_neighbors[i][3][1] = temp_label\n",
    "\n",
    "    CN = []\n",
    "    CN = list(set(nodes_neighbors[i][0]) & set(nodes_neighbors[most_important[i]][0]))\n",
    "\n",
    "    for j in CN:\n",
    "        nodes_neighbors[j][3][1] = temp_label\n",
    "        nodes_neighbors[j][3][2] = 1\n",
    "\n",
    "        nodes_neighbors[i][3][2] = 1\n",
    "        nodes_neighbors[most_important[i]][3][2] = 1\n",
    "\n",
    "\n",
    "del most_important\n",
    "del CN\n",
    "# --------------------------------- Balanced Label diffusion ------------------------------------------------\n",
    "flag_lock = 1\n",
    "counter = 1\n",
    "high = 0\n",
    "low = N - 1\n",
    "nodes_key = list(nodes_neighbors.keys())\n",
    "\n",
    "while counter < (N + 1):\n",
    "\n",
    "    if flag_lock == 1:\n",
    "        current_node = nodes_key[high]\n",
    "        high = high + 1\n",
    "        flag_lock = 0\n",
    "\n",
    "        if nodes_neighbors[current_node][1] > 1:\n",
    "\n",
    "            if nodes_neighbors[current_node][3][2] == 0:\n",
    "\n",
    "                current_node_neighbor = []\n",
    "                for j in nodes_neighbors[current_node][0]:\n",
    "                    current_node_neighbor.append((j, nodes_neighbors[j][3][1]))\n",
    "\n",
    "                sorted_input = sorted(current_node_neighbor, key=itemgetter(1))\n",
    "                groups = groupby(sorted_input, key=itemgetter(1))\n",
    "\n",
    "                neighbors_influence = []\n",
    "\n",
    "                for i in groups:\n",
    "                    sum_values = 0\n",
    "                    for j in i[1]:\n",
    "\n",
    "                        sum_values = sum_values + nodes_neighbors[j[0]][3][0]\n",
    "                    neighbors_influence.append((i[0], sum_values))\n",
    "                nodes_neighbors[current_node][3][1] = max(neighbors_influence, key=itemgetter(1))[0]\n",
    "\n",
    "    elif flag_lock == 0:\n",
    "\n",
    "        current_node = nodes_key[low]\n",
    "        low = low - 1\n",
    "        flag_lock = 1\n",
    "\n",
    "        if nodes_neighbors[current_node][1] > 1:\n",
    "\n",
    "            if nodes_neighbors[current_node][3][2] == 0:\n",
    "\n",
    "                current_node_neighbor = []\n",
    "                for j in nodes_neighbors[current_node][0]:\n",
    "                    current_node_neighbor.append((j, nodes_neighbors[j][3][1]))\n",
    "\n",
    "                sorted_input = sorted(current_node_neighbor, key=itemgetter(1))\n",
    "                groups = []\n",
    "                groups = groupby(sorted_input, key=itemgetter(1))\n",
    "\n",
    "                neighbors_influence = []\n",
    "\n",
    "                for i in groups:\n",
    "                    sum_values = 0\n",
    "                    for j in i[1]:\n",
    "                        sum_values = sum_values + (nodes_neighbors[current_node][1] * nodes_neighbors[j[0]][1])\n",
    "                    neighbors_influence.append((i[0], sum_values))\n",
    "                nodes_neighbors[current_node][3][1] = max(neighbors_influence, key=itemgetter(1))[0]\n",
    "    counter += 1\n",
    "del groups\n",
    "del neighbors_influence\n",
    "\n",
    "# ----------------------------- Give labels to nodes with degree=1 ---------------------------------\n",
    "        \n",
    "for i in range(N):\n",
    "    if nodes_neighbors[i][1] == 1:\n",
    "        nodes_neighbors[i][3][1] = nodes_neighbors[nodes_neighbors[i][0][0]][3][1]\n",
    "# ---------------------Label selection step (the iterative part of algorithm) ---------------------\n",
    "\n",
    "for itter in range(iteration):\n",
    "    for i in range(N):\n",
    "        if nodes_neighbors[i][1] > 1:\n",
    "            current_node_neighbor = []\n",
    "\n",
    "            for j in nodes_neighbors[i][0]:\n",
    "                current_node_neighbor.append((j, nodes_neighbors[j][3][1]))  # neighbors with their label\n",
    "            sorted_input = sorted(current_node_neighbor, key=itemgetter(1))\n",
    "            groups = []\n",
    "            groups = groupby(sorted_input, key=itemgetter(1))  # nodes are grouped based on their community label\n",
    "\n",
    "            neighbors_frequency = []\n",
    "            for j in groups:\n",
    "                neighbors_frequency.append((j[0], len(list(j[1]))))  # Labels frequency\n",
    "\n",
    "            temp_max = max(neighbors_frequency, key=itemgetter(1))  # label with highest frequency\n",
    "            indices = []\n",
    "            indices = [x for x, y in enumerate(neighbors_frequency) if y[1] == temp_max[1]]\n",
    "\n",
    "            selected_label = []\n",
    "            if len(indices) == 1:\n",
    "                selected_label = temp_max[0]\n",
    "            else:\n",
    "                final_max = []\n",
    "                max_influence = []\n",
    "                for x in indices:\n",
    "                    final_max.append(neighbors_frequency[x][0])  # stores only labels with highest frequency\n",
    "\n",
    "                for x in final_max:\n",
    "                    temp_influence = 1\n",
    "                    for y in current_node_neighbor:\n",
    "                        if y[1] == x:\n",
    "                            temp_influence = temp_influence * nodes_neighbors[y[0]][3][0]\n",
    "                    max_influence.append((x, temp_influence))\n",
    "\n",
    "                selected_label = max(max_influence, key=itemgetter(1))[0]\n",
    "            nodes_neighbors[i][3][1] = selected_label\n",
    "# ---------------------------------- Merge Small communities -------------------------------------------------\n",
    "if merge_flag == 1:\n",
    "\n",
    "    nodes_labels = DataFrame.from_dict(nodes_neighbors, orient='index')\n",
    "    nodes_labels.columns = ['Neighbor','Degree', 'max_Similar', 'NI_Label', 'node_NeighborLabel']\n",
    "    unique_labels = nodes_labels['NI_Label'].apply(lambda x: x[1]).unique()\n",
    "\n",
    "    communities_group = {}\n",
    "    for i in unique_labels:\n",
    "        communities_group[i] = []\n",
    "\n",
    "    for i in range(N):\n",
    "        communities_group[nodes_neighbors[i][3][1]].append(i)  # nodes are grouped their communities\n",
    "\n",
    "    unique_labels_array = []\n",
    "    for i in communities_group:\n",
    "        temp_len = len(communities_group[i])\n",
    "        if temp_len > 1:\n",
    "            unique_labels_array.append((i, temp_len))\n",
    "\n",
    "    max_community = max(unique_labels_array, key=itemgetter(1))[1]  # community with biggest size\n",
    "    average_size = (N - max_community) / (len(unique_labels_array) - 1)  # average size of communities\n",
    "\n",
    "    less_than_average_communities = []\n",
    "    less_than_average_communities = list(filter(lambda x: x[1] < average_size, unique_labels_array))\n",
    "\n",
    "    if less_than_average_communities:\n",
    "\n",
    "        for i in less_than_average_communities:\n",
    "            temp_small_communities = []\n",
    "\n",
    "            for j in communities_group[i[0]]:\n",
    "                temp_small_communities.append((j, nodes_neighbors[j][1] + nodes_neighbors[j][3][0]))\n",
    "\n",
    "            candidate_node = []\n",
    "            candidate_node = max(temp_small_communities, key=itemgetter(1))[0]  # candidate node of community\n",
    "\n",
    "            temp_neighbors = []\n",
    "            for j in nodes_neighbors[candidate_node][0]:\n",
    "                temp_neighbors.append((j, nodes_neighbors[j][1] + nodes_neighbors[j][3][0]))  # neighbors with their score\n",
    "\n",
    "            max_neighbor_community = max(temp_neighbors, key=itemgetter(1))[0]  # neighbor with maximum score\n",
    "            selected_label = []\n",
    "            if nodes_neighbors[max_neighbor_community][3][1] != nodes_neighbors[candidate_node][3][1]:\n",
    "                if nodes_neighbors[max_neighbor_community][1] >= nodes_neighbors[candidate_node][1]:\n",
    "                    selected_label = nodes_neighbors[max_neighbor_community][3][1]\n",
    "            if selected_label:\n",
    "                for j in temp_small_communities:\n",
    "                    nodes_neighbors[j[0]][3][1] = selected_label\n",
    "\n",
    "# -------------------------------Total Time of Algorithm----------------------------------------------------------------------\n",
    "print(\"--- Total Execution time %s seconds ---\" % (time.time() - start_time))\n",
    "#----------------------------------- Write to Disk ------------------------------------------------------\n",
    "ordered_nodes_neighbors = collections.OrderedDict(sorted(nodes_neighbors.items()))\n",
    "if write_flag == 1:\n",
    "    with open('./results/' + dataset_name + '.txt', 'w') as filehandle:\n",
    "        for i in ordered_nodes_neighbors:\n",
    "            filehandle.write('%s\\n' % ordered_nodes_neighbors[i][3][1])\n",
    "\n",
    "# ---------------------------------- Number of communities --------------------------------\n",
    "nodes_labels = []\n",
    "nodes_labels = DataFrame.from_dict(nodes_neighbors, orient='index')\n",
    "nodes_labels.columns = ['Neighbor','Degree', 'max_Similar', 'NI_Label', 'node_NeighborLabel']\n",
    "number_of_communities = nodes_labels['NI_Label'].apply(lambda x: x[1]).unique()\n",
    "print(\"Number of Communities: \", len(number_of_communities))\n",
    "# ----------------------------------- Modularity -------------------------------------------------------\n",
    "if modularity_flag ==1:\n",
    "    t = 0\n",
    "    for i in nodes_neighbors:\n",
    "        t = t + nodes_neighbors[i][1]\n",
    "    edges = t / 2\n",
    "    modu = 0\n",
    "    are_neighbor = []\n",
    "\n",
    "    for i in range(N):\n",
    "\n",
    "        for j in range(N):\n",
    "            if nodes_neighbors[i][3][1] == nodes_neighbors[j][3][1]:\n",
    "                if nodes_neighbors[i][1] >= 1:\n",
    "\n",
    "                    if j in nodes_neighbors[i][0]:\n",
    "                        are_neighbor = 1\n",
    "                    else:\n",
    "                        are_neighbor = 0\n",
    "                    modu = modu + (are_neighbor - ((nodes_neighbors[i][1] * nodes_neighbors[j][1]) / (2 * edges)))\n",
    "\n",
    "    modularity_final = modu / (2 * edges)\n",
    "    print('Modularity:  {}'.format(modularity_final))\n",
    "# ------------------------------- NMI ---------------------------------------\n",
    "if NMI_flag ==1:\n",
    "    real_labels= loadtxt(\"./groundtruth/\"+dataset_name+\"_real_labels.txt\", comments=\"#\", delimiter=\"\\t\", unpack=False)\n",
    "    detected_labels = []\n",
    "    if dataset_name in ('karate','dolphins','polbooks','football'):\n",
    "   \n",
    "        for i in ordered_nodes_neighbors:\n",
    "            detected_labels.append(ordered_nodes_neighbors[i][3][1])\n",
    "    \n",
    "        detected_labels=np.array(detected_labels)\n",
    "        print('NMI:  {}'.format(normalized_mutual_info_score(real_labels,detected_labels)))\n",
    "    \n",
    "    else:\n",
    "        nodes_map = loadtxt(\"./datasets/nodes_map/\" + dataset_name + \"_nodes_map.txt\", comments=\"#\", delimiter=\"\\t\", unpack=False)\n",
    "\n",
    "        for i in nodes_map:\n",
    "            detected_labels.append(nodes_neighbors[i][3][1])\n",
    "    \n",
    "        print('NMI:  {}'.format(normalized_mutual_info_score(real_labels,detected_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
